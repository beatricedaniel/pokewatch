# PokeWatch - Quick Reference Card

## ğŸš€ Common Commands

```bash
# DATA COLLECTION
make collect              # Collect latest card prices
make dvc-status          # Check data changes
make dvc-push            # Upload data to DagsHub

# TRAINING
make train               # Train model (logs to DagsHub MLflow)
make pipeline            # Run full pipeline (collect â†’ preprocess â†’ train)

# API
make api                 # Start API server (port 8000)
make api-dev             # Start with hot-reload

# TESTING
make test                # Run all tests
make test-unit           # Unit tests only

# UTILITIES
make help                # Show all commands
make clean               # Clean temp files
make docker-build        # Rebuild all images
```

## ğŸ“Š View Results

**DagsHub (Primary):**
- Experiments: https://dagshub.com/beatricedaniel/pokewatch/experiments
- Data: https://dagshub.com/beatricedaniel/pokewatch/data
- MLflow UI: https://dagshub.com/beatricedaniel/pokewatch.mlflow

**Local API:**
- API Docs: http://localhost:8000/docs
- Health: http://localhost:8000/health

## ğŸ”§ Configuration Files

| File | Purpose |
|------|---------|
| `.env` | Environment variables (API keys, DagsHub token) |
| `config/settings.yaml` | Model thresholds, paths |
| `config/cards.yaml` | Tracked cards list |
| `dvc.yaml` | Pipeline definition |

## ğŸ³ Docker Services

| Service | Command | Purpose |
|---------|---------|---------|
| **collector** | `make collect` | Fetch card prices |
| **training** | `make train` | Train models |
| **api** | `make api` | Serve predictions |
| **mlflow** (optional) | `make mlflow-local` | Local MLflow for offline dev |

## ğŸ“ Typical Workflows

### Daily Data Collection
```bash
make collect             # Fetch latest prices
make dvc-push           # Upload to DagsHub
git add dvc.lock
git commit -m "data: Update daily prices"
git push
```

### Experiment with New Threshold
```bash
# 1. Edit config
vim config/settings.yaml  # Change buy_threshold_pct

# 2. Train model
make train

# 3. View on DagsHub
open https://dagshub.com/beatricedaniel/pokewatch/experiments

# 4. If good, commit config
git add config/settings.yaml
git commit -m "exp: Test buy threshold -15%"
git push
```

### Full Pipeline Run
```bash
make pipeline            # Collect â†’ Preprocess â†’ Train
make dvc-push           # Upload data + models
git add dvc.lock
git commit -m "pipeline: Full run with updated data"
git push
```

### Deploy API
```bash
make api                 # Start API server
# OR for production:
docker-compose up -d api  # Detached mode
```

## ğŸ” Troubleshooting

| Issue | Solution |
|-------|----------|
| "Authentication failed" | Check `DAGSHUB_TOKEN` in `.env` |
| "Experiments not on DagsHub" | Verify `MLFLOW_TRACKING_URI` in `.env` |
| "Data not found" | Run `make dvc-pull` to download data |
| "API key invalid" | Update `POKEMON_PRICE_API_KEY` in `.env` |
| "Docker build fails" | Run `make docker-clean && make docker-build` |

## ğŸ“š Documentation

- **Getting Started**: `MLOPS.md` â†’ Quick Start Guide
- **Migration**: `MIGRATION_GUIDE.md`
- **API Usage**: `API_USAGE.md`
- **Docker**: `DOCKER.md`
- **This Summary**: `PHASE2_STEP3_SUMMARY.md`

## ğŸ¯ Quick Health Check

```bash
# 1. Check environment
cat .env | grep DAGSHUB_TOKEN  # Should show token

# 2. Check Docker
docker ps                      # See running containers

# 3. Check DVC
make dvc-status               # See data status

# 4. Test API
curl http://localhost:8000/health  # If API running

# 5. Check latest experiment
open https://dagshub.com/beatricedaniel/pokewatch/experiments
```

## ğŸ” Environment Variables

**Required:**
```bash
POKEMON_PRICE_API_KEY=your_api_key_here
DAGSHUB_TOKEN=your_dagshub_token_here
```

**DagsHub MLflow (auto-set):**
```bash
MLFLOW_TRACKING_URI=https://dagshub.com/beatricedaniel/pokewatch.mlflow
MLFLOW_TRACKING_USERNAME=beatricedaniel
```

**Optional (for local development):**
```bash
ENV=dev                        # dev, test, prod, training
LOG_LEVEL=INFO                 # DEBUG, INFO, WARNING, ERROR
```

## ğŸ¨ Project Structure

```
pokewatch/
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ settings.yaml    # Model config
â”‚   â””â”€â”€ cards.yaml       # Tracked cards
â”œâ”€â”€ data/                # Data (DVC-tracked)
â”‚   â”œâ”€â”€ raw/            # API responses
â”‚   â””â”€â”€ processed/      # Features
â”œâ”€â”€ models/              # Models (DVC-tracked)
â”‚   â””â”€â”€ baseline/       # Baseline model artifacts
â”œâ”€â”€ docker/              # Docker configurations
â”‚   â”œâ”€â”€ api.Dockerfile
â”‚   â”œâ”€â”€ collector.Dockerfile
â”‚   â””â”€â”€ training.Dockerfile
â”œâ”€â”€ src/pokewatch/       # Source code
â”‚   â”œâ”€â”€ api/            # FastAPI application
â”‚   â”œâ”€â”€ data/           # Data collection/processing
â”‚   â”œâ”€â”€ models/         # Model training
â”‚   â””â”€â”€ core/           # Business logic
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ scripts/             # Utility scripts
â”œâ”€â”€ Makefile            # Command orchestration
â””â”€â”€ dvc.yaml            # DVC pipeline definition
```

## ğŸ’¡ Tips

1. **Always use `make` commands** - they handle environment setup and error checking
2. **Check DagsHub after training** - experiments appear immediately
3. **Use `make dvc-status` before `make dvc-push`** - see what will be uploaded
4. **For offline work** - use `make mlflow-local` to start local MLflow
5. **Git commit DVC files** - always commit `dvc.lock` and `.dvc` files
6. **Check logs** - `docker-compose logs training` for troubleshooting

## ğŸš¨ Emergency Commands

```bash
# Stop all containers
docker-compose down

# Clean everything
make clean
make docker-clean

# Reset to fresh state
git pull
make dvc-pull
make setup

# Force rebuild
docker-compose build --no-cache training
```

---

**Need help?** Run `make help` or check `MLOPS.md`
